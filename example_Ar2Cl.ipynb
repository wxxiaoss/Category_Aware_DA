{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47bc16-5544-4af6-99ba-0624c68d9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Sequence, Tuple\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sklearn.neural_network\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "from scipy.linalg import cho_solve, cho_factor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "\n",
    "from dataset import fetch_data\n",
    "from eval import Evaluator\n",
    "from utils import nearest_pd\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from typing import Sequence\n",
    "\n",
    "from dataset import fetch_data, DataTemplate\n",
    "from eval import Evaluator\n",
    "from model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "tsk = 'Ar2Cl_CLUE'\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fe42c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q 'reps/dannrep.zip' -d reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e03ebab2-123e-4ea8-8369-e03500500341",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load('./reps/'+tsk+'/source_emb.npy')\n",
    "train_y = np.load('./reps/'+tsk+'/source_lab.npy')\n",
    "val_x = np.load('./reps/'+tsk+'/target_emb.npy')\n",
    "val_y = np.load('./reps/'+tsk+'/target_lab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f8c54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(train_x, train_y, val_x, val_y, one_idx, C):\n",
    "    model = LogisticRegression(C)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model.model.score(val_x, val_y), model.model.score(val_x[one_idx], val_y[one_idx]), f1_score(model.model.predict(val_x), val_y, average='binary'), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f5f8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_datasets(train_x, val_x, train_y, val_y, q_idxs):\n",
    "    # query new dataset and retrain\n",
    "    train_x_new = np.concatenate((train_x, val_x[q_idxs]))\n",
    "    train_y_new = np.concatenate((train_y, val_y[q_idxs]))\n",
    "\n",
    "    valid_x = val_x[q_idxs]\n",
    "    valid_y = val_y[q_idxs]\n",
    "\n",
    "    val_x_new = np.delete(val_x, q_idxs, axis=0)\n",
    "    val_y_new = np.delete(val_y, q_idxs, axis=0)\n",
    "    \n",
    "    return  train_x_new, val_x_new, train_y_new, val_y_new, valid_x, valid_y\n",
    "\n",
    "def retrain_model(train_x_new, train_y_new, val_x, val_y, one_idx, C, weights=None):\n",
    "    model = LogisticRegression(C)\n",
    "    \n",
    "    #weights[:-n] = 1 / weights[:-n].shape[0]\n",
    "    #weights[-n:] = 1 / n\n",
    "    model.fit(train_x_new, train_y_new, sample_weight=weights)\n",
    "    \n",
    "    return model.model.score(val_x, val_y), model.model.score(val_x[one_idx], val_y[one_idx]), f1_score(model.model.predict(val_x), val_y, average='binary'), model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9b81e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infl_pred(model, train_x_new, val_x_new, train_y_new, val_y_new, valid_x, valid_y, weights=None):\n",
    "    # ori_util_loss_val = model.log_loss(valid_x, valid_y)\n",
    "    # pred_train, _ = model.pred(train_x_new)\n",
    "\n",
    "    train_total_grad, train_indiv_grad = model.grad(train_x_new, train_y_new, sample_weight=weights)\n",
    "    util_loss_total_grad, acc_loss_indiv_grad = model.grad(valid_x, valid_y)\n",
    "\n",
    "    hess = model.hess(train_x_new, sample_weight=weights)\n",
    "\n",
    "    util_grad_hvp = model.get_inv_hvp(hess, util_loss_total_grad)\n",
    "    util_pred_infl = train_indiv_grad.dot(util_grad_hvp)\n",
    "\n",
    "    # print(util_pred_infl.shape)\n",
    "    # compute source infl and predict target infl\n",
    "    src_infl = util_pred_infl\n",
    "    src_infl = list(src_infl.reshape(-1))\n",
    "    reg = GradientBoostingRegressor(n_estimators=1000, \n",
    "                                    max_depth=6, \n",
    "                                    learning_rate=0.05, \n",
    "                                    max_features=0.1, \n",
    "                                    min_samples_split=25, \n",
    "                                    min_samples_leaf=25).fit(train_x_new, src_infl)\n",
    "\n",
    "    tar_infl = reg.predict(val_x_new)\n",
    "    pred_infl = reg.predict(train_x_new)\n",
    "    \n",
    "\n",
    "    return src_infl, pred_infl, tar_infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(train_x, train_y, val_x, val_y, one):\n",
    "\n",
    "    train_y = np.where(train_y == one, 1, 0)\n",
    "    val_y = np.where(val_y == one, 1, 0)\n",
    "    one_train = train_y==1\n",
    "    one_idx = val_y==1\n",
    "    \n",
    "    L2_WEIGHT = 1e-4\n",
    "    C = 1 / (train_x[0].shape[0] * L2_WEIGHT)\n",
    "    \n",
    "    src_acc = []\n",
    "    acc, acc_one, f1 = [], [], []\n",
    "    aa, sa, fa, model = train_and_eval(train_x, train_y, val_x, val_y, one_idx, C)\n",
    "    ori_pred = model.model.predict(val_x[one_idx])\n",
    "    ori_one = sa\n",
    "    \n",
    "    src_acc.append(model.model.score(train_x[one_train], train_y[one_train]))\n",
    "    # ori_src = model.model.predict(train_x[one_train])\n",
    "    \n",
    "    n = int(val_x.shape[0]*0.01)\n",
    "    # q_idxs = np.random.choice(range(len(val_x)), n)  \n",
    "\n",
    "    pred_ones = (model.model.predict(val_x)==1).astype(int)\n",
    "    one_ratio = 1.0 \n",
    "    qones = min(int(n*one_ratio), pred_ones.sum())\n",
    "\n",
    "    if qones == 0:\n",
    "        one_idxs = np.argpartition(model.model.predict_proba(val_x)[:, 1], -int(n*one_ratio))[-int(n*one_ratio):]\n",
    "    else:\n",
    "        one_idxs = np.random.choice(range(len(val_x)), qones, replace=False, p=pred_ones/np.sum(pred_ones))\n",
    "    \n",
    "    rest_idxs = np.setdiff1d(range(len(val_x)), one_idxs)\n",
    "    rest_idxs = np.random.choice(rest_idxs, n-one_idxs.shape[0], replace=False)\n",
    "    q_idxs = np.concatenate((one_idxs, rest_idxs))\n",
    "    \n",
    "    train_x_new, val_x_new, train_y_new, val_y_new, valid_x, valid_y = update_datasets(train_x, val_x, train_y, val_y, q_idxs)\n",
    "    # print(np.unique(train_y_new, return_counts=True))\n",
    "    \n",
    "\n",
    "    # no weights the first round \n",
    "    Ns = train_x.shape[0]\n",
    "    n_t_l = q_idxs.shape[0]\n",
    "    weight_BAL = None   \n",
    "    aa, sa, fa, model = retrain_model(train_x_new, train_y_new, val_x, val_y, one_idx, C)\n",
    "    acc.append(aa)\n",
    "    acc_one.append(sa)\n",
    "    f1.append(fa)\n",
    "    src_acc.append(model.model.score(train_x[one_train], train_y[one_train]))\n",
    "    # print(train_x_new.shape)\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(2, 6): \n",
    "        # q_idxs = np.random.choice(range(len(val_x_new)), n)\n",
    "        src_infl, pred_infl, tar_infl = infl_pred(model, train_x_new, val_x_new, train_y_new, val_y_new, valid_x, valid_y, weights=weight_BAL)\n",
    "        q_idxs = np.argpartition(tar_infl, -n)[-n:]\n",
    "        n_t_l += q_idxs.shape[0]\n",
    "        weight_BAL = np.r_[np.ones(Ns), Ns/n_t_l*np.ones(n_t_l)] \n",
    "         \n",
    "        train_x_new, val_x_new, train_y_new, val_y_new, valid_x, valid_y = update_datasets(train_x_new, val_x_new, train_y_new, val_y_new, q_idxs)      \n",
    "        \n",
    "        # calculate weights for source data\n",
    "        # src_infl = np.array(src_infl)\n",
    "        # positive_idx = np.argwhere(src_infl>0)\n",
    "        # positive_weights = softmax(src_infl[src_infl>0.])\n",
    "        # src_weights = np.ones((src_infl.shape[0],))\n",
    "        # up_weights = np.zeros((src_infl.shape[0],))\n",
    "        # up_weights[positive_idx] = positive_weights.reshape((-1,1))\n",
    "        # src_weights = src_weights + up_weights * 50.0\n",
    "\n",
    "        # # update weights for the new data\n",
    "        # weights = np.array(1.0 * train_x_new.shape[0])\n",
    "        # weights[:src_weights.shape[0]] = src_weights\n",
    "        \n",
    "        aa, sa, fa, model = retrain_model(train_x_new, train_y_new, val_x, val_y, one_idx, C, weights=weight_BAL)\n",
    "        \n",
    "        acc.append(aa)\n",
    "        acc_one.append(sa)\n",
    "        f1.append(fa)\n",
    "        src_acc.append(model.model.score(train_x[one_train], train_y[one_train]))\n",
    "        # print(train_x_new.shape)\n",
    "    \n",
    "\n",
    "    selected_labels = train_y_new[-n*5:]    \n",
    "    pred = model.model.predict(val_x[one_idx])\n",
    "    label = val_y[one_idx]\n",
    "\n",
    "    sel_y_train = train_y_new[-n*5:]\n",
    "    sel_x_train = train_x_new[-n*5:]\n",
    "\n",
    "    ori_y_train = train_y_new[:-n*5]\n",
    "    ori_x_train = train_x_new[:-n*5]\n",
    "\n",
    "    sel_none = sel_y_train==0\n",
    "    sel_y_train = sel_y_train[sel_none]\n",
    "    sel_x_train = sel_x_train[sel_none]\n",
    "\n",
    "    train_x_o = np.concatenate((ori_x_train, sel_x_train))\n",
    "    train_y_o = np.concatenate((ori_y_train, sel_y_train))\n",
    "\n",
    "    n_t_l = sel_y_train.shape[0]\n",
    "    weight_BAL = np.r_[np.ones(Ns), Ns/n_t_l*np.ones(n_t_l)]\n",
    "\n",
    "\n",
    "\n",
    "    aa, sa, fa, model = retrain_model(train_x_o, train_y_o, val_x, val_y, one_idx, C, weights=weight_BAL)\n",
    "    src_acc.append(model.model.score(train_x[one_train], train_y[one_train]))\n",
    "    pred_o = model.model.predict(val_x[one_idx])\n",
    "    label_o = val_y[one_idx]\n",
    "\n",
    "\n",
    "\n",
    "    sel_y_train = train_y_new[-n*5:]\n",
    "    sel_x_train = train_x_new[-n*5:]\n",
    "\n",
    "    ori_y_train = train_y_new[:-n*5]\n",
    "    ori_x_train = train_x_new[:-n*5]\n",
    "\n",
    "    sel_none = sel_y_train==1\n",
    "    sel_y_train = sel_y_train[sel_none]\n",
    "    sel_x_train = sel_x_train[sel_none]\n",
    "\n",
    "    train_x_1 = np.concatenate((ori_x_train, sel_x_train))\n",
    "    train_y_1 = np.concatenate((ori_y_train, sel_y_train))\n",
    "\n",
    "    n_t_l = sel_y_train.shape[0]\n",
    "    weight_BAL = np.r_[np.ones(Ns), Ns/n_t_l*np.ones(n_t_l)]\n",
    "\n",
    "\n",
    "    aa, sa, fa, model = retrain_model(train_x_1, train_y_1, val_x, val_y, one_idx, C, weights=weight_BAL)\n",
    "    src_acc.append(model.model.score(train_x[one_train], train_y[one_train]))\n",
    "    pred_1 = model.model.predict(val_x[one_idx])\n",
    "    label_1 = val_y[one_idx]\n",
    "\n",
    "\n",
    "\n",
    "    return src_acc, acc, ori_one, acc_one, f1, ori_pred, pred, label, selected_labels, pred_o, label_o, pred_1, label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e6044c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "ori_ones = []\n",
    "acc_ones = []\n",
    "src_accs = []\n",
    "selected_lebels = []\n",
    "\n",
    "for j in range(65):\n",
    "    src_acc, acc, ori_one, acc_one, f1, ori_pred, pred, label, selected = active_learning(train_x, train_y, val_x, val_y, j)\n",
    "    ori_ones.append(ori_one)\n",
    "    acc_ones.append(acc_one)\n",
    "    src_accs.append(src_acc)\n",
    "    selected_lebels.append(selected)\n",
    "\n",
    "    if j == 0:\n",
    "        ori_preds = ori_pred\n",
    "        preds = pred\n",
    "        labels = label\n",
    "    else:\n",
    "        ori_preds = np.concatenate((ori_preds, ori_pred))\n",
    "        preds = np.concatenate((preds, pred))\n",
    "        labels = np.concatenate((labels, label))\n",
    "\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e694a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d236fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same start 1.0 Ar2Cl_CLUE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3699885452462772, 0.6914089347079038)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"same start 1.0\", tsk)\n",
    "(ori_preds == labels).sum() / len(preds), (preds == labels).sum() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895affc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3615d3-8a69-4d75-88c1-0cbc9ab9b963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba946015-691e-4e52-848f-b07173a8f0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1eb93-5bad-4bbb-88c7-9973a34fe15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a680f2-22d1-49e9-93a6-f73f4ee27c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a59c6-3c1b-4f6d-9847-c00157f99632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98804278-1424-4a28-87df-605e9b22a2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e3005-a9cc-428f-8257-92b4ceb8b0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31614e4d-4bd1-4eb9-8704-0ac34cdf317e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
